Index: linux-2.6.37.1.x/fs/ext4/Kconfig
===================================================================
--- linux-2.6.37.1.x.orig/fs/ext4/Kconfig	2010-11-29 12:45:04.000000000 +0530
+++ linux-2.6.37.1.x/fs/ext4/Kconfig	2010-11-29 12:45:46.000000000 +0530
@@ -214,3 +214,12 @@
 	  The move block command maps an allocated blocks to the snapshot file,
 	  allocating only the indirect blocks when needed.
 	  This mechanism is used to move-on-write data blocks to snapshot.
+
+config EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+	bool "snapshot block operation - copy block bitmap to snapshot"
+	depends on EXT4_FS_SNAPSHOT_BLOCK
+	default y
+	help
+	  The snapshot copy of the file system block bitmap is called the COW
+	  bitmap and it is used to check if a block was allocated at the time
+	  that the snapshot was taken.
Index: linux-2.6.37.1.x/fs/ext4/snapshot.c
===================================================================
--- linux-2.6.37.1.x.orig/fs/ext4/snapshot.c	2010-11-29 12:45:04.000000000 +0530
+++ linux-2.6.37.1.x/fs/ext4/snapshot.c	2010-11-29 12:45:46.000000000 +0530
@@ -152,6 +152,28 @@
 	set_buffer_uptodate(sbh);
 }
 
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+/*
+ * use @mask to clear exclude bitmap bits from block bitmap
+ * when creating COW bitmap and mark snapshot buffer @sbh uptodate
+ */
+static inline void
+__ext4_snapshot_copy_bitmap(struct buffer_head *sbh,
+		char *dst, const char *src, const char *mask)
+{
+	const u32 *ps = (const u32 *)src, *pm = (const u32 *)mask;
+	u32 *pd = (u32 *)dst;
+	int i;
+
+	if (mask) {
+		for (i = 0; i < SNAPSHOT_ADDR_PER_BLOCK; i++)
+			*pd++ = *ps++ & ~*pm++;
+	} else
+		memcpy(dst, src, SNAPSHOT_BLOCK_SIZE);
+
+	set_buffer_uptodate(sbh);
+}
+#endif
 
 /*
  * ext4_snapshot_complete_cow()
@@ -208,13 +230,246 @@
 		struct buffer_head *bh, const char *mask)
 {
 	lock_buffer(sbh);
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+	if (mask)
+		__ext4_snapshot_copy_bitmap(sbh,
+				sbh->b_data, bh->b_data, mask);
+	else
+		__ext4_snapshot_copy_buffer(sbh, bh);
+#else
 	__ext4_snapshot_copy_buffer(sbh, bh);
+#endif
 	unlock_buffer(sbh);
 	mark_buffer_dirty(sbh);
 	sync_dirty_buffer(sbh);
 }
 
 
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+/*
+ * COW bitmap functions
+ */
+
+/*
+ * ext4_snapshot_init_cow_bitmap() init a new allocated (locked) COW bitmap
+ * buffer on first time block group access after snapshot take.
+ * COW bitmap is created by masking the block bitmap with exclude bitmap.
+ */
+static int
+ext4_snapshot_init_cow_bitmap(struct super_block *sb,
+		unsigned int block_group, struct buffer_head *cow_bh)
+{
+	struct buffer_head *bitmap_bh;
+	char *dst, *src, *mask = NULL;
+	struct journal_head *jh;
+
+	bitmap_bh = read_block_bitmap(sb, block_group);
+	if (!bitmap_bh)
+		return -EIO;
+
+	src = bitmap_bh->b_data;
+	/*
+	 * Another COWing task may be changing this block bitmap
+	 * (allocating active snapshot blocks) while we are trying
+	 * to copy it.  Copying committed_data will keep us
+	 * protected from these changes.  At this point we are
+	 * guaranteed that the only difference between block bitmap
+	 * and committed_data are the new active snapshot blocks,
+	 * because before allocating/freeing any other blocks a task
+	 * must first get_undo_access() and get here.
+	 */
+	jbd_lock_bh_journal_head(bitmap_bh);
+	jbd_lock_bh_state(bitmap_bh);
+	jh = bh2jh(bitmap_bh);
+	if (jh && jh->b_committed_data)
+		src = jh->b_committed_data;
+
+	/*
+	 * in the path coming from ext4_snapshot_read_block_bitmap(),
+	 * cow_bh is a user page buffer so it has to be kmapped.
+	 */
+	dst = kmap_atomic(cow_bh->b_page, KM_USER0);
+	__ext4_snapshot_copy_bitmap(cow_bh, dst, src, mask);
+	kunmap_atomic(dst, KM_USER0);
+
+	jbd_unlock_bh_state(bitmap_bh);
+	jbd_unlock_bh_journal_head(bitmap_bh);
+
+	brelse(bitmap_bh);
+	return 0;
+}
+
+/*
+ * ext4_snapshot_read_block_bitmap()
+ * helper function for ext4_snapshot_get_block()
+ * used for fixing the block bitmap user page buffer when
+ * reading through to block device.
+ */
+int ext4_snapshot_read_block_bitmap(struct super_block *sb,
+		unsigned int block_group, struct buffer_head *bitmap_bh)
+{
+	int err;
+
+	lock_buffer(bitmap_bh);
+	err = ext4_snapshot_init_cow_bitmap(sb, block_group, bitmap_bh);
+	unlock_buffer(bitmap_bh);
+	return err;
+}
+
+/*
+ * ext4_snapshot_read_cow_bitmap - read COW bitmap from active snapshot
+ * @handle:	JBD handle
+ * @snapshot:	active snapshot
+ * @block_group: block group
+ *
+ * Reads the COW bitmap block (i.e., the active snapshot copy of block bitmap).
+ * Creates the COW bitmap on first access to @block_group after snapshot take.
+ * COW bitmap cache is non-persistent, so no need to mark the group descriptor
+ * block dirty.  COW bitmap races are handled internally, so no locks are
+ * required when calling this function, only a valid @handle.
+ *
+ * Return COW bitmap buffer on success or NULL in case of failure.
+ */
+static struct buffer_head *
+ext4_snapshot_read_cow_bitmap(handle_t *handle, struct inode *snapshot,
+			       unsigned int block_group)
+{
+	struct super_block *sb = snapshot->i_sb;
+	struct ext4_sb_info *sbi = EXT4_SB(sb);
+	struct ext4_group_info *gi = sbi->s_snapshot_group_info + block_group;
+	struct ext4_group_desc *desc;
+	struct buffer_head *cow_bh;
+	ext4_fsblk_t bitmap_blk;
+	ext4_fsblk_t cow_bitmap_blk;
+	int err = 0;
+
+	desc = ext4_get_group_desc(sb, block_group, NULL);
+	if (!desc)
+		return NULL;
+
+	bitmap_blk = ext4_block_bitmap(sb, desc);
+
+	ext4_lock_group(sb, block_group);
+	cow_bitmap_blk = gi->bg_cow_bitmap;
+	ext4_unlock_group(sb, block_group);
+	if (cow_bitmap_blk)
+		return sb_bread(sb, cow_bitmap_blk);
+
+	/*
+	 * Try to read cow bitmap block from snapshot file.  If COW bitmap
+	 * is not yet allocated, create the new COW bitmap block.
+	 */
+	cow_bh = ext4_bread(handle, snapshot, SNAPSHOT_IBLOCK(bitmap_blk),
+				SNAPMAP_READ, &err);
+	if (cow_bh)
+		goto out;
+
+	/* allocate snapshot block for COW bitmap */
+	cow_bh = ext4_getblk(handle, snapshot, SNAPSHOT_IBLOCK(bitmap_blk),
+				SNAPMAP_BITMAP, &err);
+	if (!cow_bh || err < 0)
+		goto out;
+	if (!err) {
+		/*
+		 * err should be 1 to indicate new allocated (locked) buffer.
+		 * if err is 0, it means that someone mapped this block
+		 * before us, while we are updating the COW bitmap cache.
+		 * the pending COW bitmap code should prevent that.
+		 */
+		WARN_ON(1);
+		err = -EIO;
+		goto out;
+	}
+
+	err = ext4_snapshot_init_cow_bitmap(sb, block_group, cow_bh);
+	if (err)
+		goto out;
+	/*
+	 * complete pending COW operation. no need to wait for tracked reads
+	 * of block bitmap, because it is copied directly to page buffer by
+	 * ext4_snapshot_read_block_bitmap()
+	 */
+	err = ext4_snapshot_complete_cow(handle, cow_bh, NULL, 1);
+	if (err)
+		goto out;
+
+	trace_cow_inc(handle, bitmaps);
+out:
+	if (!err && cow_bh) {
+		/* initialized COW bitmap block */
+		cow_bitmap_blk = cow_bh->b_blocknr;
+		snapshot_debug(3, "COW bitmap #%u of snapshot (%u) "
+				"mapped to block [%lld/%lld]\n",
+				block_group, snapshot->i_generation,
+				SNAPSHOT_BLOCK_GROUP_OFFSET(cow_bitmap_blk),
+				SNAPSHOT_BLOCK_GROUP(cow_bitmap_blk));
+	} else {
+		/* uninitialized COW bitmap block */
+		cow_bitmap_blk = 0;
+		snapshot_debug(1, "failed to read COW bitmap #%u of snapshot "
+				"(%u)\n", block_group, snapshot->i_generation);
+		brelse(cow_bh);
+		cow_bh = NULL;
+	}
+
+	/* update or reset COW bitmap cache */
+	ext4_lock_group(sb, block_group);
+	gi->bg_cow_bitmap = cow_bitmap_blk;
+	ext4_unlock_group(sb, block_group);
+
+	return cow_bh;
+}
+
+/*
+ * ext4_snapshot_test_cow_bitmap - test if blocks are in use by snapshot
+ * @handle:	JBD handle
+ * @snapshot:	active snapshot
+ * @block:	address of block
+ * @maxblocks:	max no. of blocks to be tested
+ * @excluded:	if not NULL, blocks belong to this excluded inode
+ *
+ * If the block bit is set in the COW bitmap, than it was allocated at the time
+ * that the active snapshot was taken and is therefore "in use" by the snapshot.
+ *
+ * Return values:
+ * > 0 - no. of blocks that are in use by snapshot
+ * = 0 - @block is not in use by snapshot
+ * < 0 - error
+ */
+static int
+ext4_snapshot_test_cow_bitmap(handle_t *handle, struct inode *snapshot,
+		ext4_fsblk_t block, int maxblocks, struct inode *excluded)
+{
+	struct buffer_head *cow_bh;
+	unsigned long block_group = SNAPSHOT_BLOCK_GROUP(block);
+	ext4_grpblk_t bit = SNAPSHOT_BLOCK_GROUP_OFFSET(block);
+	ext4_fsblk_t snapshot_blocks = SNAPSHOT_BLOCKS(snapshot);
+	int inuse;
+
+	if (block >= snapshot_blocks)
+		/*
+		 * Block is not is use by snapshot because it is past the
+		 * last f/s block at the time that the snapshot was taken.
+		 * (suggests that f/s was resized after snapshot take)
+		 */
+		return 0;
+
+	cow_bh = ext4_snapshot_read_cow_bitmap(handle, snapshot, block_group);
+	if (!cow_bh)
+		return -EIO;
+	/*
+	 * if the bit is set in the COW bitmap,
+	 * then the block is in use by snapshot
+	 */
+	for (inuse = 0; inuse < maxblocks && bit+inuse <
+			 SNAPSHOT_BLOCKS_PER_GROUP; inuse++) {
+		if (!ext4_test_bit(bit+inuse, cow_bh->b_data))
+			break;
+	}
+
+	return inuse;
+}
+#endif
 
 
 /*
@@ -337,8 +592,16 @@
 		cow = 0;
 	}
 
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+	/* get the COW bitmap and test if blocks are in use by snapshot */
+	err = ext4_snapshot_test_cow_bitmap(handle, active_snapshot,
+			block, 1, clear < 0 ? inode : NULL);
+	if (err < 0)
+		goto out;
+#else
 	if (clear < 0)
 		goto cowed;
+#endif
 	if (!err) {
 		trace_cow_inc(handle, ok_bitmap);
 		goto cowed;
@@ -460,8 +723,17 @@
 		move = 0;
 	}
 
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+	/* get the COW bitmap and test if blocks are in use by snapshot */
+	err = ext4_snapshot_test_cow_bitmap(handle, active_snapshot,
+			block, count, excluded ? inode : NULL);
+	if (err < 0)
+		goto out;
+	count = err;
+#else
 	if (excluded)
 		goto out;
+#endif
 	if (!err) {
 		/* block not in COW bitmap - no need to move */
 		trace_cow_inc(handle, ok_bitmap);
Index: linux-2.6.37.1.x/fs/ext4/snapshot_ctl.c
===================================================================
--- linux-2.6.37.1.x.orig/fs/ext4/snapshot_ctl.c	2010-11-29 12:19:39.000000000 +0530
+++ linux-2.6.37.1.x/fs/ext4/snapshot_ctl.c	2010-11-29 12:48:14.000000000 +0530
@@ -90,7 +90,31 @@
 }
 #endif
 
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+/*
+ * ext4_snapshot_reset_bitmap_cache():
+ *
+ * Resets the COW/exclude bitmap cache for all block groups.
+ *
+ * Called from init_bitmap_cache() with @init=1 under sb_lock during mount time.
+ * Called from snapshot_take() with @init=0 under journal_lock_updates().
+ * Returns 0 on success and <0 on error.
+ */
+static int ext4_snapshot_reset_bitmap_cache(struct super_block *sb, int init)
+{
+	struct ext4_group_info *gi = EXT4_SB(sb)->s_snapshot_group_info;
+	int i;
+
+	for (i = 0; i < EXT4_SB(sb)->s_groups_count; i++, gi++) {
+		gi->bg_cow_bitmap = 0;
+		if (init)
+			gi->bg_exclude_bitmap = 0;
+	}
+	return 0;
+}
+#else
 #define ext4_snapshot_reset_bitmap_cache(sb, init) 0
+#endif
 
 
 /*
Index: linux-2.6.37.1.x/fs/ext4/snapshot.h
===================================================================
--- linux-2.6.37.1.x.orig/fs/ext4/snapshot.h	2010-11-29 12:45:04.000000000 +0530
+++ linux-2.6.37.1.x/fs/ext4/snapshot.h	2010-11-29 12:45:46.000000000 +0530
@@ -215,7 +215,15 @@
 static inline int ext4_snapshot_get_undo_access(handle_t *handle,
 		struct buffer_head *bh)
 {
+#ifdef CONFIG_EXT4_FS_SNAPSHOT_BLOCK_BITMAP
+	/*
+	 * undo access is only requested for block bitmaps, which should be
+	 * COWed in ext4_snapshot_test_cow_bitmap(), even if we pass @cow=0.
+	 */
+	return ext4_snapshot_cow(handle, NULL, bh, 0);
+#else
 	return ext4_snapshot_cow(handle, NULL, bh, 1);
+#endif
 }
 
 /*
