===next3_snapshot_block_bitmap.patch===

next3: snapshot block operation - copy block bitmap to snapshot

The snapshot copy of the file system block bitmap is called the COW
bitmap and it is used to check if a block was allocated at the time
that the snapshot was taken.

Signed-off-by: Amir Goldstein <amir73il@users.sf.net>

--------------------------------------------------------------------------------
diff -Nuarp a/fs/next3/snapshot.c b/fs/next3/snapshot.c
--- a/fs/next3/snapshot.c	2010-07-26 09:22:02.514921841 +0300
+++ b/fs/next3/snapshot.c	2010-07-26 09:22:02.004914953 +0300
@@ -141,6 +141,26 @@ __next3_snapshot_copy_buffer(struct buff
 	set_buffer_uptodate(sbh);
 }
 
+/*
+ * use @mask to clear exclude bitmap bits from block bitmap
+ * when creating COW bitmap and mark snapshot buffer @sbh uptodate
+ */
+static inline void
+__next3_snapshot_copy_bitmap(struct buffer_head *sbh,
+		char *dst, const char *src, const char *mask)
+{
+	const u32 *ps = (const u32 *)src, *pm = (const u32 *)mask;
+	u32 *pd = (u32 *)dst;
+	int i;
+
+	if (mask) {
+		for (i = 0; i < SNAPSHOT_ADDR_PER_BLOCK; i++)
+			*pd++ = *ps++ & ~*pm++;
+	} else
+		memcpy(dst, src, SNAPSHOT_BLOCK_SIZE);
+
+	set_buffer_uptodate(sbh);
+}
 
 /*
  * next3_snapshot_complete_cow()
@@ -194,13 +214,240 @@ void next3_snapshot_copy_buffer(struct b
 		struct buffer_head *bh, const char *mask)
 {
 	lock_buffer(sbh);
-	__next3_snapshot_copy_buffer(sbh, bh);
+	if (mask)
+		__next3_snapshot_copy_bitmap(sbh,
+				sbh->b_data, bh->b_data, mask);
+	else
+		__next3_snapshot_copy_buffer(sbh, bh);
 	unlock_buffer(sbh);
 	mark_buffer_dirty(sbh);
 	sync_dirty_buffer(sbh);
 }
 
 
+/*
+ * COW bitmap functions
+ */
+
+/*
+ * next3_snapshot_init_cow_bitmap() init a new allocated (locked) COW bitmap
+ * buffer on first time block group access after snapshot take.
+ * COW bitmap is created by masking the block bitmap with exclude bitmap.
+ */
+static int
+next3_snapshot_init_cow_bitmap(struct super_block *sb,
+		unsigned int block_group, struct buffer_head *cow_bh)
+{
+	struct buffer_head *bitmap_bh;
+	char *dst, *src, *mask = NULL;
+	struct journal_head *jh;
+
+	bitmap_bh = read_block_bitmap(sb, block_group);
+	if (!bitmap_bh)
+		return -EIO;
+
+	src = bitmap_bh->b_data;
+	/*
+	 * Another COWing task may be changing this block bitmap
+	 * (allocating active snapshot blocks) while we are trying
+	 * to copy it.  Copying committed_data will keep us
+	 * protected from these changes.  At this point we are
+	 * guaranteed that the only difference between block bitmap
+	 * and committed_data are the new active snapshot blocks,
+	 * because before allocating/freeing any other blocks a task
+	 * must first get_undo_access() and get here.
+	 */
+	jbd_lock_bh_journal_head(bitmap_bh);
+	jbd_lock_bh_state(bitmap_bh);
+	jh = bh2jh(bitmap_bh);
+	if (jh && jh->b_committed_data)
+		src = jh->b_committed_data;
+
+	/*
+	 * in the path coming from next3_snapshot_read_block_bitmap(),
+	 * cow_bh is a user page buffer so it has to be kmapped.
+	 */
+	dst = kmap_atomic(cow_bh->b_page, KM_USER0);
+	__next3_snapshot_copy_bitmap(cow_bh, dst, src, mask);
+	kunmap_atomic(dst, KM_USER0);
+
+	jbd_unlock_bh_state(bitmap_bh);
+	jbd_unlock_bh_journal_head(bitmap_bh);
+
+	brelse(bitmap_bh);
+	return 0;
+}
+
+/*
+ * next3_snapshot_read_block_bitmap()
+ * helper function for next3_snapshot_get_block()
+ * used for fixing the block bitmap user page buffer when
+ * reading through to block device.
+ */
+int next3_snapshot_read_block_bitmap(struct super_block *sb,
+		unsigned int block_group, struct buffer_head *bitmap_bh)
+{
+	int err;
+
+	lock_buffer(bitmap_bh);
+	err = next3_snapshot_init_cow_bitmap(sb, block_group, bitmap_bh);
+	unlock_buffer(bitmap_bh);
+	return err;
+}
+
+/*
+ * next3_snapshot_read_cow_bitmap - read COW bitmap from active snapshot
+ * @handle:	JBD handle
+ * @snapshot:	active snapshot
+ * @block_group: block group
+ *
+ * Reads the COW bitmap block (i.e., the active snapshot copy of block bitmap).
+ * Creates the COW bitmap on first access to @block_group after snapshot take.
+ * COW bitmap cache is non-persistent, so no need to mark the group descriptor
+ * block dirty.  COW bitmap races are handled internally, so no locks are
+ * required when calling this function, only a valid @handle.
+ *
+ * Return COW bitmap buffer on success or NULL in case of failure.
+ */
+static struct buffer_head *
+next3_snapshot_read_cow_bitmap(handle_t *handle, struct inode *snapshot,
+			       unsigned int block_group)
+{
+	struct super_block *sb = snapshot->i_sb;
+	struct next3_sb_info *sbi = NEXT3_SB(sb);
+	struct next3_group_info *gi = sbi->s_group_info + block_group;
+	struct next3_group_desc *desc;
+	struct buffer_head *cow_bh;
+	next3_fsblk_t bitmap_blk;
+	next3_fsblk_t cow_bitmap_blk;
+	int err = 0;
+
+	desc = next3_get_group_desc(sb, block_group, NULL);
+	if (!desc)
+		return NULL;
+
+	bitmap_blk = le32_to_cpu(desc->bg_block_bitmap);
+
+	spin_lock(sb_bgl_lock(sbi, block_group));
+	cow_bitmap_blk = gi->bg_cow_bitmap;
+	spin_unlock(sb_bgl_lock(sbi, block_group));
+	if (cow_bitmap_blk)
+		return sb_bread(sb, cow_bitmap_blk);
+
+	/*
+	 * Try to read cow bitmap block from snapshot file.  If COW bitmap
+	 * is not yet allocated, create the new COW bitmap block.
+	 */
+	cow_bh = next3_bread(handle, snapshot, SNAPSHOT_IBLOCK(bitmap_blk),
+				SNAPMAP_READ, &err);
+	if (cow_bh)
+		goto out;
+
+	/* allocate snapshot block for COW bitmap */
+	cow_bh = next3_getblk(handle, snapshot, SNAPSHOT_IBLOCK(bitmap_blk),
+				SNAPMAP_BITMAP, &err);
+	if (!cow_bh || err < 0)
+		goto out;
+	if (!err) {
+		/*
+		 * err should be 1 to indicate new allocated (locked) buffer.
+		 * if err is 0, it means that someone mapped this block
+		 * before us, while we are updating the COW bitmap cache.
+		 * the pending COW bitmap code should prevent that.
+		 */
+		WARN_ON(1);
+		err = -EIO;
+		goto out;
+	}
+
+	err = next3_snapshot_init_cow_bitmap(sb, block_group, cow_bh);
+	if (err)
+		goto out;
+	/*
+	 * complete pending COW operation. no need to wait for tracked reads
+	 * of block bitmap, because it is copied directly to page buffer by
+	 * next3_snapshot_read_block_bitmap()
+	 */
+	err = next3_snapshot_complete_cow(handle, cow_bh, NULL, 1);
+	if (err)
+		goto out;
+
+	trace_cow_inc(handle, bitmaps);
+out:
+	if (!err && cow_bh) {
+		/* initialized COW bitmap block */
+		cow_bitmap_blk = cow_bh->b_blocknr;
+		snapshot_debug(3, "COW bitmap #%u of snapshot (%u) "
+				"mapped to block [%lu/%lu]\n",
+				block_group, snapshot->i_generation,
+				SNAPSHOT_BLOCK_GROUP_OFFSET(cow_bitmap_blk),
+				SNAPSHOT_BLOCK_GROUP(cow_bitmap_blk));
+	} else {
+		/* uninitialized COW bitmap block */
+		cow_bitmap_blk = 0;
+		snapshot_debug(1, "failed to read COW bitmap #%u of snapshot "
+				"(%u)\n", block_group, snapshot->i_generation);
+		brelse(cow_bh);
+		cow_bh = NULL;
+	}
+
+	/* update or reset COW bitmap cache */
+	spin_lock(sb_bgl_lock(sbi, block_group));
+	gi->bg_cow_bitmap = cow_bitmap_blk;
+	spin_unlock(sb_bgl_lock(sbi, block_group));
+
+	return cow_bh;
+}
+
+/*
+ * next3_snapshot_test_cow_bitmap - test if blocks are in use by snapshot
+ * @handle:	JBD handle
+ * @snapshot:	active snapshot
+ * @block:	address of block
+ * @maxblocks:	max no. of blocks to be tested
+ * @excluded:	if not NULL, blocks belong to this excluded inode
+ *
+ * If the block bit is set in the COW bitmap, than it was allocated at the time
+ * that the active snapshot was taken and is therefore "in use" by the snapshot.
+ *
+ * Return values:
+ * > 0 - no. of blocks that are in use by snapshot
+ * = 0 - @block is not in use by snapshot
+ * < 0 - error
+ */
+static int
+next3_snapshot_test_cow_bitmap(handle_t *handle, struct inode *snapshot,
+		next3_fsblk_t block, int maxblocks, struct inode *excluded)
+{
+	struct buffer_head *cow_bh;
+	unsigned long block_group = SNAPSHOT_BLOCK_GROUP(block);
+	next3_grpblk_t bit = SNAPSHOT_BLOCK_GROUP_OFFSET(block);
+	int snapshot_blocks = SNAPSHOT_BLOCKS(snapshot);
+	int inuse;
+
+	if (block >= snapshot_blocks)
+		/*
+		 * Block is not is use by snapshot because it is past the
+		 * last f/s block at the time that the snapshot was taken.
+		 * (suggests that f/s was resized after snapshot take)
+		 */
+		return 0;
+
+	cow_bh = next3_snapshot_read_cow_bitmap(handle, snapshot, block_group);
+	if (!cow_bh)
+		return -EIO;
+	/*
+	 * if the bit is set in the COW bitmap,
+	 * then the block is in use by snapshot
+	 */
+	for (inuse = 0; inuse < maxblocks && bit+inuse < SNAPSHOT_BLOCKS_PER_GROUP;
+			inuse++) {
+		if (!next3_test_bit(bit+inuse, cow_bh->b_data))
+			break;
+	}
+
+	return inuse;
+}
 
 
 /*
@@ -323,8 +570,11 @@ int next3_snapshot_test_and_cow(const ch
 		cow = 0;
 	}
 
-	if (clear < 0)
-		goto cowed;
+	/* get the COW bitmap and test if blocks are in use by snapshot */
+	err = next3_snapshot_test_cow_bitmap(handle, active_snapshot,
+			block, 1, clear < 0 ? inode : NULL);
+	if (err < 0)
+		goto out;
 	if (!err) {
 		trace_cow_inc(handle, ok_bitmap);
 		goto cowed;
@@ -444,8 +694,12 @@ int next3_snapshot_test_and_move(const c
 		move = 0;
 	}
 
-	if (excluded)
+	/* get the COW bitmap and test if blocks are in use by snapshot */
+	err = next3_snapshot_test_cow_bitmap(handle, active_snapshot,
+			block, count, excluded ? inode : NULL);
+	if (err < 0)
 		goto out;
+	count = err;
 	if (!err) {
 		/* block not in COW bitmap - no need to move */
 		trace_cow_inc(handle, ok_bitmap);
diff -Nuarp a/fs/next3/snapshot_ctl.c b/fs/next3/snapshot_ctl.c
--- a/fs/next3/snapshot_ctl.c	2010-07-26 09:22:02.524921073 +0300
+++ b/fs/next3/snapshot_ctl.c	2010-07-26 09:22:02.004914953 +0300
@@ -88,7 +88,27 @@ static int next3_snapshot_set_active(str
 	return 0;
 }
 
-#define next3_snapshot_reset_bitmap_cache(sb, init) 0
+/*
+ * next3_snapshot_reset_bitmap_cache():
+ *
+ * Resets the COW/exclude bitmap cache for all block groups.
+ *
+ * Called from init_bitmap_cache() with @init=1 under sb_lock during mount time.
+ * Called from snapshot_take() with @init=0 under journal_lock_updates().
+ * Returns 0 on success and <0 on error.
+ */
+static int next3_snapshot_reset_bitmap_cache(struct super_block *sb, int init)
+{
+	struct next3_group_info *gi = NEXT3_SB(sb)->s_group_info;
+	int i;
+
+	for (i = 0; i < NEXT3_SB(sb)->s_groups_count; i++, gi++) {
+		gi->bg_cow_bitmap = 0;
+		if (init)
+			gi->bg_exclude_bitmap = 0;
+	}
+	return 0;
+}
 
 
 /*
diff -Nuarp a/fs/next3/snapshot.h b/fs/next3/snapshot.h
--- a/fs/next3/snapshot.h	2010-07-26 09:22:02.524921073 +0300
+++ b/fs/next3/snapshot.h	2010-07-26 09:22:02.014913251 +0300
@@ -191,7 +191,11 @@ static inline int next3_snapshot_get_wri
 static inline int next3_snapshot_get_undo_access(handle_t *handle,
 		struct buffer_head *bh)
 {
-	return next3_snapshot_cow(handle, NULL, bh, 1);
+	/*
+	 * undo access is only requested for block bitmaps, which should be
+	 * COWed in next3_snapshot_test_cow_bitmap(), even if we pass @cow=0.
+	 */
+	return next3_snapshot_cow(handle, NULL, bh, 0);
 }
 
 /*
