===next3_snapshot_ctl_init.patch===

next3: snapshot control - init new snapshot

On snapshot create, a few special blocks (i.e., the super block and
group descriptors) are pre-allocated and on snapshot take, they are
copied under journal_lock_updates().  This is done to avoid the
recursion that would be caused by COWing these blocks after the
snapshot becomes active.

Signed-off-by: Amir Goldstein <amir73il@users.sf.net>

--------------------------------------------------------------------------------
diff -Nuarp a/fs/next3/snapshot_ctl.c b/fs/next3/snapshot_ctl.c
--- a/fs/next3/snapshot_ctl.c	2010-07-26 09:22:01.484907006 +0300
+++ b/fs/next3/snapshot_ctl.c	2010-07-26 09:22:00.964900702 +0300
@@ -298,6 +298,48 @@ static int __extend_or_restart_transacti
 #define extend_or_restart_transaction_inode(handle, inode, nblocks)	\
 	__extend_or_restart_transaction(__func__, (handle), (inode), (nblocks))
 
+/*
+ * helper function for snapshot_create().
+ * places pre-allocated [d,t]ind blocks in position
+ * after they have been allocated as direct blocks.
+ */
+static inline int next3_snapshot_shift_blocks(struct next3_inode_info *ei,
+		int from, int to, int count)
+{
+	int i, err = -EIO;
+
+	/* move from direct blocks range */
+	BUG_ON(from < 0 || from + count > NEXT3_NDIR_BLOCKS);
+	/* to indirect blocks range */
+	BUG_ON(to < NEXT3_NDIR_BLOCKS || to + count > NEXT3_SNAPSHOT_N_BLOCKS);
+
+	/*
+	 * truncate_mutex is held whenever allocating or freeing inode
+	 * blocks.
+	 */
+	mutex_lock(&ei->truncate_mutex);
+
+	/*
+	 * verify that 'from' blocks are allocated
+	 * and that 'to' blocks are not allocated.
+	 */
+	for (i = 0; i < count; i++)
+		if (!ei->i_data[from+i] ||
+				ei->i_data[to+i])
+			goto out;
+
+	/*
+	 * shift 'count' blocks from position 'from' to 'to'
+	 */
+	for (i = 0; i < count; i++) {
+		ei->i_data[to+i] = ei->i_data[from+i];
+		ei->i_data[from+i] = 0;
+	}
+	err = 0;
+out:
+	mutex_unlock(&ei->truncate_mutex);
+	return err;
+}
 
 /*
  * next3_snapshot_create() initializes a snapshot file
@@ -312,6 +354,13 @@ static int next3_snapshot_create(struct 
 	struct inode *active_snapshot = next3_snapshot_has_active(sb);
 	struct next3_inode_info *ei = NEXT3_I(inode);
 	int i, err, ret;
+	int count, nind;
+	const long double_blocks = (1 << (2 * SNAPSHOT_ADDR_PER_BLOCK_BITS));
+	struct buffer_head *bh = NULL;
+	struct next3_group_desc *desc;
+	unsigned long ino;
+	struct next3_iloc iloc;
+	next3_fsblk_t bmap_blk = 0, imap_blk = 0, inode_blk = 0;
 	loff_t snapshot_blocks = le32_to_cpu(sbi->s_es->s_blocks_count);
 	if (active_snapshot) {
 		snapshot_debug(1, "failed to add snapshot because active "
@@ -394,6 +443,140 @@ static int next3_snapshot_create(struct 
 	if (err)
 		goto out_handle;
 
+	/* small filesystems can be mapped with just 1 double indirect block */
+	nind = 1;
+	if (snapshot_blocks > double_blocks)
+		/* add up to 4 triple indirect blocks to map 2^32 blocks */
+		nind += ((snapshot_blocks - double_blocks) >>
+			(3 * SNAPSHOT_ADDR_PER_BLOCK_BITS)) + 1;
+	if (nind > NEXT3_SNAPSHOT_NTIND_BLOCKS + 1) {
+		snapshot_debug(1, "need too many [d,t]ind blocks (%d) "
+				"for snapshot (%u)\n",
+				nind, inode->i_generation);
+		err = -EFBIG;
+		goto out_handle;
+	}
+
+	err = extend_or_restart_transaction_inode(handle, inode,
+			nind * NEXT3_DATA_TRANS_BLOCKS(sb));
+	if (err)
+		goto out_handle;
+
+	/* pre-allocate and zero out [d,t]ind blocks */
+	for (i = 0; i < nind; i++) {
+		brelse(bh);
+		bh = next3_getblk(handle, inode, i, SNAPMAP_WRITE, &err);
+		if (!bh || err)
+			break;
+		/* zero out indirect block and journal as dirty metadata */
+		err = next3_journal_get_write_access(handle, bh);
+		if (err)
+			break;
+		lock_buffer(bh);
+		memset(bh->b_data, 0, bh->b_size);
+		set_buffer_uptodate(bh);
+		unlock_buffer(bh);
+		err = next3_journal_dirty_metadata(handle, bh);
+		if (err)
+			break;
+	}
+	brelse(bh);
+	if (!bh || err) {
+		snapshot_debug(1, "failed to initiate [d,t]ind block (%d) "
+				"for snapshot (%u)\n",
+				i, inode->i_generation);
+		goto out_handle;
+	}
+	/* place pre-allocated [d,t]ind blocks in position */
+	err = next3_snapshot_shift_blocks(ei, 0, NEXT3_DIND_BLOCK, nind);
+	if (err) {
+		snapshot_debug(1, "failed to move pre-allocated [d,t]ind blocks"
+				" for snapshot (%u)\n",
+				inode->i_generation);
+		goto out_handle;
+	}
+
+	/* allocate super block and group descriptors for snapshot */
+	count = sbi->s_gdb_count + 1;
+	err = count;
+	for (i = 0; err > 0 && i < count; i += err) {
+		err = extend_or_restart_transaction_inode(handle, inode,
+				NEXT3_DATA_TRANS_BLOCKS(sb));
+		if (err)
+			goto out_handle;
+		err = next3_snapshot_map_blocks(handle, inode, i, count - i,
+						NULL, SNAPMAP_WRITE);
+	}
+	if (err <= 0) {
+		snapshot_debug(1, "failed to allocate super block and %d "
+			       "group descriptor blocks for snapshot (%u)\n",
+			       count - 1, inode->i_generation);
+		if (err)
+			err = -EIO;
+		goto out_handle;
+	}
+
+	ino = inode->i_ino;
+	/*
+	 * pre-allocate the following blocks in the new snapshot:
+	 * - block and inode bitmap blocks of ino's block group
+	 * - inode table block that contains ino
+	 */
+	err = extend_or_restart_transaction_inode(handle, inode,
+			3 * NEXT3_DATA_TRANS_BLOCKS(sb));
+	if (err)
+		goto out_handle;
+
+	iloc.block_group = 0;
+	inode_blk = next3_get_inode_block(sb, ino, &iloc);
+	bmap_blk = 0;
+	imap_blk = 0;
+	desc = next3_get_group_desc(sb, iloc.block_group, NULL);
+	if (!desc)
+		goto next_snapshot;
+
+	bmap_blk = le32_to_cpu(desc->bg_block_bitmap);
+	imap_blk = le32_to_cpu(desc->bg_inode_bitmap);
+	if (!bmap_blk || !imap_blk)
+		goto next_snapshot;
+
+	count = 1;
+	if (imap_blk == bmap_blk + 1)
+		count++;
+	if (inode_blk == imap_blk + 1)
+		count++;
+	/* try to allocate all blocks at once */
+	err = next3_snapshot_map_blocks(handle, inode,
+			bmap_blk, count,
+			NULL, SNAPMAP_WRITE);
+	count = err;
+	/* allocate remaining blocks one by one */
+	if (err > 0 && count < 2)
+		err = next3_snapshot_map_blocks(handle, inode,
+				imap_blk, 1,
+				NULL,
+				SNAPMAP_WRITE);
+	if (err > 0 && count < 3)
+		err = next3_snapshot_map_blocks(handle, inode,
+				inode_blk, 1,
+				NULL,
+				SNAPMAP_WRITE);
+next_snapshot:
+	if (!bmap_blk || !imap_blk || !inode_blk || err < 0) {
+#ifdef CONFIG_NEXT3_FS_DEBUG
+		next3_fsblk_t blk0 = iloc.block_group *
+			NEXT3_BLOCKS_PER_GROUP(sb);
+		snapshot_debug(1, "failed to allocate block/inode bitmap "
+				"or inode table block of inode (%lu) "
+				"(%lu,%lu,%lu/%lu) for snapshot (%u)\n",
+				ino, bmap_blk - blk0,
+				imap_blk - blk0, inode_blk - blk0,
+				iloc.block_group, inode->i_generation);
+#endif
+		if (!err)
+			err = -EIO;
+		goto out_handle;
+	}
 
 	snapshot_debug(1, "snapshot (%u) created\n", inode->i_generation);
 	err = 0;
@@ -412,6 +595,68 @@ out_handle:
  */
 static handle_t dummy_handle;
 
+/*
+ * next3_snapshot_copy_block() - copy block to new snapshot
+ * @snapshot:	new snapshot to copy block to
+ * @bh:		source buffer to be copied
+ * @mask:	if not NULL, mask buffer data before copying to snapshot
+ * 		(used to mask block bitmap with exclude bitmap)
+ * @name:	name of copied block to print
+ * @idx:	index of copied block to print
+ *
+ * Called from next3_snapshot_take() under journal_lock_updates()
+ * Returns snapshot buffer on success, NULL on error
+ */
+static struct buffer_head *next3_snapshot_copy_block(struct inode *snapshot,
+		struct buffer_head *bh, const char *mask,
+		const char *name, unsigned long idx)
+{
+	struct buffer_head *sbh = NULL;
+	int err;
+
+	if (!bh)
+		return NULL;
+
+	sbh = next3_getblk(&dummy_handle, snapshot,
+			SNAPSHOT_IBLOCK(bh->b_blocknr),
+			SNAPMAP_READ, &err);
+
+	if (err || !sbh || sbh->b_blocknr == bh->b_blocknr) {
+		snapshot_debug(1, "failed to copy %s (%lu) "
+				"block [%lu/%lu] to snapshot (%u)\n",
+				name, idx,
+				SNAPSHOT_BLOCK_TUPLE(bh->b_blocknr),
+				snapshot->i_generation);
+		brelse(sbh);
+		return NULL;
+	}
+
+	next3_snapshot_copy_buffer(sbh, bh, mask);
+
+	snapshot_debug(4, "copied %s (%lu) block [%lu/%lu] "
+			"to snapshot (%u)\n",
+			name, idx,
+			SNAPSHOT_BLOCK_TUPLE(bh->b_blocknr),
+			snapshot->i_generation);
+	return sbh;
+}
+
+/*
+ * List of blocks which are copied to snapshot for every special inode.
+ * Keep block bitmap first and inode table block last in the list.
+ */
+enum copy_inode_block {
+	COPY_BLOCK_BITMAP,
+	COPY_INODE_BITMAP,
+	COPY_INODE_TABLE,
+	COPY_INODE_BLOCKS_NUM
+};
+
+static char *copy_inode_block_name[COPY_INODE_BLOCKS_NUM] = {
+	"block bitmap",
+	"inode bitmap",
+	"inode table"
+};
 
 /*
  * next3_snapshot_take() makes a new snapshot file
@@ -427,6 +672,12 @@ int next3_snapshot_take(struct inode *in
 	struct next3_sb_info *sbi = NEXT3_SB(sb);
 	struct next3_super_block *es = NULL;
 	struct buffer_head *sbh = NULL;
+	struct buffer_head *bhs[COPY_INODE_BLOCKS_NUM] = { NULL };
+	const char *mask = NULL;
+	struct inode *curr_inode;
+	struct next3_iloc iloc;
+	struct next3_group_desc *desc;
+	int i;
 	int err = -EIO;
 
 	if (!sbi->s_sbh)
@@ -473,6 +724,59 @@ int next3_snapshot_take(struct inode *in
 	}
 #endif
 
+	/*
+	 * copy super block to snapshot and fix it
+	 */
+	lock_buffer(sbh);
+	memcpy(sbh->b_data, sbi->s_sbh->b_data, sb->s_blocksize);
+	set_buffer_uptodate(sbh);
+	unlock_buffer(sbh);
+	mark_buffer_dirty(sbh);
+	sync_dirty_buffer(sbh);
+
+	/*
+	 * copy group descriptors to snapshot
+	 */
+	for (i = 0; i < sbi->s_gdb_count; i++) {
+		brelse(sbh);
+		sbh = next3_snapshot_copy_block(inode,
+				sbi->s_group_desc[i], NULL,
+				"GDT", i);
+		if (!sbh)
+			goto out_unlockfs;
+	}
+
+	curr_inode = inode;
+	/*
+	 * copy the following blocks to the new snapshot:
+	 * - block and inode bitmap blocks of curr_inode block group
+	 * - inode table block that contains curr_inode
+	 */
+	iloc.block_group = 0;
+	err = next3_get_inode_loc(curr_inode, &iloc);
+	desc = next3_get_group_desc(sb, iloc.block_group, NULL);
+	if (err || !desc) {
+		snapshot_debug(1, "failed to read inode and bitmap blocks "
+			       "of inode (%lu)\n", curr_inode->i_ino);
+		err = err ? : -EIO;
+		goto out_unlockfs;
+	}
+	for (i = 0; i < COPY_INODE_BLOCKS_NUM; i++)
+		brelse(bhs[i]);
+	bhs[COPY_BLOCK_BITMAP] = sb_bread(sb,
+			le32_to_cpu(desc->bg_block_bitmap));
+	bhs[COPY_INODE_BITMAP] = sb_bread(sb,
+			le32_to_cpu(desc->bg_inode_bitmap));
+	bhs[COPY_INODE_TABLE] = iloc.bh;
+	err = -EIO;
+	for (i = 0; i < COPY_INODE_BLOCKS_NUM; i++) {
+		brelse(sbh);
+		sbh = next3_snapshot_copy_block(inode, bhs[i], mask,
+				copy_inode_block_name[i], curr_inode->i_ino);
+		if (!sbh)
+			goto out_unlockfs;
+		mask = NULL;
+	}
 
 	/* reset COW bitmap cache */
 	err = next3_snapshot_reset_bitmap_cache(sb, 0);
@@ -504,6 +808,8 @@ out_unlockfs:
 
 out_err:
 	brelse(sbh);
+	for (i = 0; i < COPY_INODE_BLOCKS_NUM; i++)
+		brelse(bhs[i]);
 	return err;
 }
 
